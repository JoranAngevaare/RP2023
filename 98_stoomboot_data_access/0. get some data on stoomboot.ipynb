{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open spectrum from root-files \n",
    "\n",
    "# Not an exercise for students! \n",
    "Author:\n",
    "\n",
    "J. Angevaare // <j.angevaare@nikhef.nl> // 2020-05-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have only been dealing with small files that make it easy to see what is going on. Perhaps we want at some point to get more data from the stoomboot computing cluster or the appended root-file as in this folder. This notebook will show how to and we make an exemplary coincidence plot for Ti-44 using much more data than in the previous tutorials.\n",
    "\n",
    "Below we:\n",
    " - locate a file on the stoomboot computing cluster\n",
    " - open it using uproot\n",
    " - show a calibrated spectrum\n",
    " - show a Ti-44 coincidence plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (ONLY ON NIKEF CLUSTER)\n",
    "## Locating file:\n",
    "check where files live on stoomboot (NB: will only work on stoomboot not on your machine!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:34:39.281085Z",
     "start_time": "2021-01-03T15:34:39.276877Z"
    }
   },
   "outputs": [],
   "source": [
    "def on_stoomboot():\n",
    "    '''Check that you can do stuff here otherwise raise an error'''\n",
    "    host = socket.gethostname()\n",
    "    if not 'nikhef' in host:\n",
    "        raise ValueError(f'You are not on stoomboot but on {host}. '\n",
    "                          'You can not do this operation! Perhaps continue below')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mx_n_20200104_1055\r\n",
      "mx_n_20200106_0821\r\n",
      "mx_n_20200110_0847\r\n",
      "mx_n_20200114_0815\r\n",
      "mx_n_20200117_0916\r\n",
      "mx_n_20200120_0644\r\n",
      "mx_n_20200124_1141\r\n"
     ]
    }
   ],
   "source": [
    "# this is where files are stored (let's \"grep\" something from january this year)\n",
    "on_stoomboot()\n",
    "!ls /data/modulation/Raw_Data/combined/ | grep 202001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--.  1 jorana xenon  80M Jan  6 11:01 mx_n_20200104_1055_000051.root\r\n",
      "-rw-r--r--.  1 jorana xenon  80M Jan  6 11:02 mx_n_20200104_1055_000052.root\r\n",
      "-rw-r--r--.  1 jorana xenon  80M Jan  6 11:02 mx_n_20200104_1055_000053.root\r\n",
      "-rw-r--r--.  1 jorana xenon  80M Jan  6 11:03 mx_n_20200104_1055_000054.root\r\n",
      "-rw-r--r--.  1 jorana xenon  38M Jan  6 11:03 mx_n_20200104_1055_000055.root\r\n"
     ]
    }
   ],
   "source": [
    "# this is where processed root files live, lets look at the top folder of the list above\n",
    "on_stoomboot()\n",
    "!ls -lthr /dcache/xenon/tmons/Modulation/processed/mx_n_20200104_1055 | tail -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's copy that last one as it is not too big\n",
    "on_stoomboot()\n",
    "!cp '/dcache/xenon/tmons/Modulation/processed/mx_n_20200104_1055/mx_n_20200104_1055_000055.root' ../data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.5G\r\n",
      "-rw-r--r--. 1 jorana xenon 3.9M Jun  7 21:33 Co60_sample.csv\r\n",
      "drwxr-xr-x. 2 jorana xenon 4.0K Jun  7 22:01 bg\r\n",
      "drwxr-xr-x. 2 jorana xenon 4.0K Jun  7 22:01 ti44\r\n",
      "drwxr-xr-x. 2 jorana xenon 4.0K Jun  7 22:01 co60\r\n",
      "drwxr-xr-x. 2 jorana xenon 4.0K Jun  7 22:01 cs137\r\n",
      "-rw-r--r--. 1 jorana xenon  64M Jun  7 22:01 bg_dat.zip\r\n",
      "-rw-r--r--. 1 jorana xenon 3.3G Jun  7 22:02 ti44_dat.zip\r\n",
      "-rw-r--r--. 1 jorana xenon 843M Jun  7 22:02 co60_dat.zip\r\n",
      "-rw-r--r--. 1 jorana xenon 1.3G Jun  7 22:02 cs137_dat.zip\r\n",
      "drwxr-xr-x. 2 jorana xenon   80 Jun  7 22:36 copy_bg\r\n",
      "-rw-r--r--. 1 jorana xenon  58K Jun  7 22:39 copy_bg.zip\r\n",
      "-rw-r--r--. 1 jorana xenon  38M Jun  7 22:54 mx_n_20200104_1055_000055.root\r\n"
     ]
    }
   ],
   "source": [
    "on_stoomboot()\n",
    "!ls -lthr ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (BONUS)\n",
    "### Generate very large files\n",
    "As you may have seen above, this is only one of the many files we have available (there is about 50 TB so more than you want to imagine). Below, we will show what you can do to get more data but be aware, this may not be required, will take more time and make your computer unhappy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:34:00.588314Z",
     "start_time": "2021-01-03T15:34:00.351146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import tqdm\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:34:30.752555Z",
     "start_time": "2021-01-03T15:34:30.716819Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'on_stoomboot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-30431e3b3dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# NB: only works on stoomboot!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# NB: takes 20 minutes!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mon_stoomboot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroot_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dcache/xenon/tmons/Modulation/processed/mx_n_20200104_1055'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstore_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'integral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'on_stoomboot' is not defined"
     ]
    }
   ],
   "source": [
    "# Load all the data  on this path\n",
    "# NB: only works on stoomboot!\n",
    "# NB: takes 20 minutes!\n",
    "on_stoomboot()\n",
    "root_folder = '/dcache/xenon/tmons/Modulation/processed/mx_n_20200104_1055'\n",
    "store_columns = ['channel', 'integral','time']\n",
    "sources = {'bg':[0,1], 'ti44':[2,3], 'co60':[4,5], 'cs137':[6,7]}\n",
    "for root_file in tqdm.tqdm(os.listdir(root_folder)):\n",
    "    if not '.root' in root_file:\n",
    "        # This is not a rootfile\n",
    "        continue\n",
    "    else:\n",
    "        idx = root_file.split('_')[-1].split('.root')[0]\n",
    "    path = os.path.join(root_folder, root_file)\n",
    "    file = uproot.open(path)\n",
    "    tree = file['T;2']\n",
    "    data = tree.pandas.df()\n",
    "    for source, channels in sources.items():\n",
    "        mask = ( \n",
    "            (data['channel'] == channels[0] ) | (data['channel'] == channels[1] ) \n",
    "            & (data['istestpulse'] == 0) \n",
    "            & (data['error'] == 0) \n",
    "        )\n",
    "        save_dir = f'../data/{source}'\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        save_name = f'{save_dir}/{source}_chunck_{idx}.csv'\n",
    "        data[mask][store_columns].to_csv(save_name,index=False)\n",
    "    # Double check that we free up memory\n",
    "    del data, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T15:34:33.389540Z",
     "start_time": "2021-01-03T15:34:33.386031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alright, let me zip this data for you. After that you can download it on your own laptop\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 133.19it/s]\n",
      "100%|██████████| 56/56 [00:20<00:00,  2.67it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.64it/s]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's zip al the dat a in these files\n",
    "on_stoomboot()\n",
    "for source in sources.keys():\n",
    "    save_dir = f'../data/{source}'\n",
    "    zipObj = zipfile.ZipFile(f'../data/{source}_dat.zip', 'w')\n",
    "    for f in tqdm.tqdm(os.listdir(save_dir)):\n",
    "        if '.csv' in f:\n",
    "            path = os.path.join(save_dir, f)\n",
    "            zipObj.write(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg_dat.zip\r\n",
      "co60_dat.zip\r\n",
      "cs137_dat.zip\r\n",
      "ti44_dat.zip\r\n"
     ]
    }
   ],
   "source": [
    "# Great our data is zipped and at:\n",
    "!ls ../data | grep zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
